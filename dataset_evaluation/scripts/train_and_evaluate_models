#!/usr/bin/env python3

import argparse
from collections import OrderedDict
import sys

import numpy as np

from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import LeaveOneGroupOut
from sklearn.preprocessing import LabelEncoder


def get_chromosomes(seqs):
    """
    Assumes that sequence names are in the format:

    chrom_start_end

    e.g., chr2L:34345_50123
    """
    chromosomes = []
    for name in seqs:
        cols = name.split(":")
        chromosomes.append(cols[0])

    return chromosomes


def read_fasta(flname):
    # since Python 3.7, LIFO is guaranteed
    # but in case this is run on an older
    # version of Python...
    sequences = OrderedDict()
    with open(flname) as fl:
        seq_name = None
        seq = ""
        for ln in fl:
            if ln.startswith(">"):
                if seq_name != None:
                    sequences[seq_name] = seq
                seq_name = ln[1:].strip().split()[0]
                seq = ""
            else:
                seq += ln.strip()

        if seq_name != None:
            sequences[seq_name] = seq

    return sequences


def filter_by_chromosome(seqs, selected_chrom):
    remaining_seq = dict()
    remaining_chrom = set()

    # we assume that the fasta files were
    # generated by our scripts and follow
    # our naming conventions
    chromosomes = get_chromosomes(seqs)

    for (name, seq), chrom in zip(seqs.items(), chromosomes):
        if chrom in selected_chrom:
            remaining_seq[name] = seq
            remaining_chrom.add(chrom)

    return remaining_chrom, remaining_seq


def write_bed(flname, seqs):
    with open(flname, "w") as fl:
        for seq_name in seqs:
            cols = seq_name.split(":")
            fl.write(cols[0])
            fl.write("\t")
            fl.write(cols[1].split("-")[0])
            fl.write("\t")
            fl.write(cols[1].split("-")[1])
            fl.write("\t")
            fl.write(seq_name)
            fl.write("\n")


def main():
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--tmnt-fasta", required=True, type=str, help="Treatment sequences"
    )

    parser.add_argument(
        "--ctrl-fasta", required=True, type=str, help="Control sequences"
    )

    parser.add_argument(
        "--reg-weight", required=True, type=float, help="L2 regularization weight"
    )

    parser.add_argument(
        "--predictions-fl",
        required=True,
        type=str,
        help="Save labels and predictions in npz format",
    )

    parser.add_argument(
        "--select-chrom",
        type=str,
        nargs="*",
        help="Only use sequences from the provided chromosomes",
    )

    parser.add_argument("--n-jobs", default=1, type=int, help="Use multiple threads")

    parser.add_argument(
        "--n-estimators",
        default=48,
        type=int,
        help="Number of models to use in ensemble",
    )

    parser.add_argument("--positive-bed-fl", type=str, required=True)

    parser.add_argument("--negative-bed-fl", type=str, required=True)

    args = parser.parse_args()

    tmnt_seq = read_fasta(args.tmnt_fasta)
    ctrl_seq = read_fasta(args.ctrl_fasta)

    if args.select_chrom:
        print(
            "Selected sequences from chromosomes {}".format(
                ", ".join(args.select_chrom)
            )
        )

        remaining_chroms = set()

        original_seqs = len(tmnt_seq) + len(ctrl_seq)

        tmnt_chrom, tmnt_seq = filter_by_chromosome(tmnt_seq, args.select_chrom)

        ctrl_chrom, ctrl_seq = filter_by_chromosome(ctrl_seq, args.select_chrom)

        remaining_chroms.update(tmnt_chrom)
        remaining_chroms.update(ctrl_chrom)

        remaining_seqs = len(tmnt_seq) + len(ctrl_seq)

        print("{} of {} total sequences remain".format(remaining_seqs, original_seqs))
        print("Remaining chromosomes: {}".format(", ".join(set(remaining_chroms))))

    # the seqs are stored in ordered dictionaries
    # so this should maintain the sequence order
    all_seq = tmnt_seq.copy()
    all_seq.update(ctrl_seq)

    labels = np.zeros(len(all_seq))
    # print(tmnt_seq)
    labels[: len(tmnt_seq)] = 1.0

    encoder = LabelEncoder()
    chromosomes = get_chromosomes(all_seq)
    # print(f"{chromosomes=}")
    groups = encoder.fit_transform(chromosomes)

    # Okay, so in theory we should do the vectorization
    # within each cross-validation fold.  But!  If a given
    # k-mer is absent from the training samples, its weight
    # will be 0 and not used in the predictions.  Therefore,
    # we get the same result either way.
    print("Vectorizing")
    vec = CountVectorizer(ngram_range=(6, 8), analyzer="char")
    # print(f"{all_seq.values()=}")

    X = vec.fit_transform(all_seq.values())

    true_y = []
    all_pred_y = []
    predicted_probs = []

    # SGD!
    sgd = SGDClassifier(loss="log_loss", alpha=args.reg_weight)
    # Bootstrapping didn't help with reducing variance or accuracy
    # Goal is to compensate for variance from random
    # weight initialization of SGD classifier
    ensemble = BaggingClassifier(
        sgd, n_estimators=args.n_estimators, bootstrap=False, n_jobs=1
    )

    # RF!
    # rf = RandomForestClassifier(n_estimators=args.n_estimators, random_state=42)
    # ensemble = BaggingClassifier(rf, n_estimators=args.n_estimators, n_jobs=1)
    logo = LeaveOneGroupOut()
    pos_seqs = dict()
    neg_seqs = dict()
    print("Model training and evaluation")
    # print(f"{X}")
    # print(labels)
    for train_idx, test_idx in logo.split(X, labels, groups=groups):
        train_X = X[train_idx]
        test_X = X[test_idx]

        train_y = labels[train_idx]
        test_y = labels[test_idx]

        target_chrom = chromosomes[test_idx[0]]
        _, target_seqs = filter_by_chromosome(tmnt_seq, [target_chrom])

        # print(f"{np.unique(train_X)=}")
        # print(f"{np.unique(train_y)=}")

        ensemble.fit(train_X, train_y)

        pred_y = ensemble.predict(test_X)
        pred_prob = ensemble.predict_proba(test_X)[:, 1]

        all_pred_y.extend(pred_y)
        predicted_probs.extend(pred_prob)
        true_y.extend(test_y)

        for prob, (seq_name, seq) in zip(pred_prob, target_seqs.items()):
            if prob >= 0.8:
                pos_seqs[seq_name] = seq
            elif prob < 0.5:
                neg_seqs[seq_name] = seq

        acc = accuracy_score(test_y, pred_y)
        print("Accuracy:", acc)

    predicted_probs = np.array(predicted_probs)
    all_pred_y = np.array(all_pred_y)
    true_y = np.array(true_y)

    acc = accuracy_score(true_y, all_pred_y)
    auc = roc_auc_score(true_y, predicted_probs)

    cm = confusion_matrix(true_y, all_pred_y)
    tn, fp, fn, tp = cm.ravel()

    fpr = fp / len(true_y[true_y == 0])
    tpr = tp / len(true_y[true_y == 1])

    print("Overall accuracy: {:.1%}".format(acc))
    print("Overall ROC AUC: {:.3f}".format(auc))
    print("TPR: {:.1%}".format(tpr))
    print("FPR: {:.1%}".format(fpr))

    np.savez(
        args.predictions_fl,
        y_true=true_y,
        pred_prob=predicted_probs,
        pred_labels=all_pred_y,
    )

    write_bed(args.positive_bed_fl, pos_seqs)

    write_bed(args.negative_bed_fl, neg_seqs)


if __name__ == "__main__":
    main()
